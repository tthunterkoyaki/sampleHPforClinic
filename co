import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
import os
import zipfile

# ---------------------------------------------------------
# 1. 集中設定 (Configuration)
# ---------------------------------------------------------
class Config:
    # --- 入出力設定 ---
    INPUT_FILE_NAME = 'input_data.csv'
    
    # --- シミュレーション設定 ---
    SIMULATION_MONTHS = 36      # 3年
    NUM_SIMULATIONS = 10000     # 試行回数
    CONFIDENCE_LEVEL = 0.05     # 95%信頼区間下限
    
    # --- ブートストラップ設定 ---
    USE_BLOCK_BOOTSTRAP = True
    BLOCK_SIZE = 1              # 1ヶ月ブロック
    
    # --- ストレス設定 ---
    # 金利差の拡大をキャップする係数 (1.0 = 現状以上には拡大させない保守的設定)
    STRESS_SPREAD_FACTOR = 1.0  
    
    # --- ビジネスパラメータ ---
    AVERAGE_MATURITY_YEARS = 7.0
    RUNOFF_RATE = 1.0 / (AVERAGE_MATURITY_YEARS * 12)
    
    REQUIRED_COLUMNS = ['Date', 'Balance_USD', 'CHF_Share', 'Interest_Spread', 'FX_Volatility', 'BDTI', 'USDJPY']

    # --- 変数定義 (モデル構造) ---
    FEATURES = [
        {'name': 'Logit_Lag1',  'type': 'lag', 'source': 'Logit_Share', 'lag': 1},
        {'name': 'Spread_Lag0', 'type': 'ext', 'source': 'Interest_Spread', 'lag': 0},
        {'name': 'Spread_Lag1', 'type': 'lag', 'source': 'Interest_Spread', 'lag': 1},
        {'name': 'Spread_Lag2', 'type': 'lag', 'source': 'Interest_Spread', 'lag': 2},
        {'name': 'Spread_Lag3', 'type': 'lag', 'source': 'Interest_Spread', 'lag': 3},
        {'name': 'FX_Vol_Lag0', 'type': 'ext', 'source': 'FX_Volatility', 'lag': 0},
        {'name': 'BDTI_Lag0',   'type': 'ext', 'source': 'BDTI', 'lag': 0},
    ]
    
    # 強制採用変数
    FORCE_INCLUDE = ['Spread', 'Logit_Lag1'] 
    
    # 変数選択の閾値
    P_VALUE_THRESHOLD = 0.20

# ---------------------------------------------------------
# 2. データ読み込み / 生成ロジック
# ---------------------------------------------------------
def load_or_generate_data():
    if os.path.exists(Config.INPUT_FILE_NAME):
        print(f"Loading input data from '{Config.INPUT_FILE_NAME}'...")
        try:
            df = pd.read_csv(Config.INPUT_FILE_NAME, parse_dates=['Date'])
            missing_cols = [c for c in Config.REQUIRED_COLUMNS if c not in df.columns]
            if missing_cols:
                raise ValueError(f"Missing columns in CSV: {missing_cols}")
            df = df.sort_values('Date').reset_index(drop=True)
            return df
        except Exception as e:
            print(f"Error loading CSV: {e}")
            print("Falling back to dummy data generation...")
            return generate_realistic_dummy_data()
    else:
        print(f"'{Config.INPUT_FILE_NAME}' not found. Generating dummy data...")
        return generate_realistic_dummy_data()

def generate_realistic_dummy_data(n_months=36):
    np.random.seed(42)
    # Pandas Future Warning対応: 'ME' (Month End)
    dates = pd.date_range(start='2022-04-01', periods=n_months, freq='ME')
    
    trend_spread = np.linspace(1.0, 4.0, n_months)
    interest_spread = trend_spread + np.random.normal(0, 0.2, n_months)
    
    usdjpy = np.linspace(120, 155, n_months) + np.cumsum(np.random.normal(0, 1.5, n_months))
    pct_change = pd.Series(usdjpy).pct_change()
    fx_vol = pct_change.rolling(6).std().fillna(0.01) * 100 * np.sqrt(12)
    
    bdti = 1000 + np.cumsum(np.random.normal(0, 50, n_months))
    
    chf_share = np.zeros(n_months)
    chf_share[0] = 0.20
    target_trend = np.linspace(0.20, 0.55, n_months)
    
    for t in range(1, n_months):
        logit_prev = np.log(chf_share[t-1] / (1 - chf_share[t-1]))
        spread_effect = 0.0 * interest_spread[t] + 0.3 * interest_spread[t-3] if t >= 3 else 0
        logit_target = np.log(target_trend[t] / (1 - target_trend[t]))
        logit_new = 0.7 * logit_prev + 0.3 * logit_target + 0.1 * spread_effect + np.random.normal(0, 0.05)
        chf_share[t] = 1 / (1 + np.exp(-logit_new))

    balance_usd = np.linspace(450, 480, n_months) + np.random.normal(0, 2, n_months)

    df = pd.DataFrame({
        'Date': dates, 'Balance_USD': balance_usd, 'CHF_Share': chf_share,
        'Interest_Spread': interest_spread, 'FX_Volatility': fx_vol.values,
        'BDTI': bdti, 'USDJPY': usdjpy
    })
    return df

def engineer_features(df_raw, config):
    df = df_raw.copy()
    df['CHF_Share_Clipped'] = df['CHF_Share'].clip(0.01, 0.99)
    df['Logit_Share'] = np.log(df['CHF_Share_Clipped'] / (1 - df['CHF_Share_Clipped']))
    
    model_cols = []
    for feat in config.FEATURES:
        col_name = feat['name']
        src = feat['source']
        lag = feat.get('lag', 0)
        base_series = df[src]
        if lag > 0: df[col_name] = base_series.shift(lag)
        else: df[col_name] = base_series
        model_cols.append(col_name)
        
    df_model = df.dropna().reset_index(drop=True)
    return df_model, model_cols

# ---------------------------------------------------------
# 3. モデル構築 & 共和分検定
# ---------------------------------------------------------
print("--- [1] Data Loading & Modeling ---")
df_raw = load_or_generate_data()
current_usdjpy = df_raw['USDJPY'].iloc[-1]
print(f"Current USD/JPY Rate: {current_usdjpy:.2f}")

df_model, X_cols = engineer_features(df_raw, Config)
y_col = 'Logit_Share'

final_vars = X_cols.copy()
y = df_model[y_col]

print("Selecting variables...")
while True:
    X = sm.add_constant(df_model[final_vars])
    model = sm.OLS(y, X).fit()
    pvalues = model.pvalues
    remove_var = None
    max_p = -1
    
    for var in final_vars:
        p = pvalues[var]
        is_protected = any(force_key in var for force_key in Config.FORCE_INCLUDE)
        if is_protected: continue
        if p > Config.P_VALUE_THRESHOLD:
            if p > max_p:
                max_p = p
                remove_var = var
    
    if remove_var:
        print(f"Dropping: {remove_var} (p={max_p:.4f})")
        final_vars.remove(remove_var)
    else:
        break

print(f"Final Model Variables: {final_vars}")
X_final = sm.add_constant(df_model[final_vars])
final_model = sm.OLS(y, X_final).fit()
print(final_model.summary())

# --- 【復活】共和分(Cointegration)の検証 ---
print("\n--- [2] Cointegration Check (ADF Test on Residuals) ---")
# ARDLモデルの残差に対してADF検定を行う
residuals = final_model.resid
adf_result = adfuller(residuals)
p_value_adf = adf_result[1]

print(f"ADF Statistic: {adf_result[0]:.4f}")
print(f"p-value: {p_value_adf:.5f}")

if p_value_adf < 0.1:
    print(">> PASS: 残差は定常です(p<0.1)。変数間に共和分関係（長期均衡）が存在し、この回帰分析は有効です。")
    print("   (見せかけの回帰ではありません)")
else:
    print(">> CAUTION: 残差が非定常の可能性があります。サンプル数を増やすか、変数の再検討が必要かもしれません。")


# ---------------------------------------------------------
# 4. ブロック・ブートストラップ・シミュレーション (全パス記録)
# ---------------------------------------------------------
print("\n--- [3] Simulation (Recording All Paths) ---")

pool_df = pd.DataFrame()
for feat in Config.FEATURES:
    if feat['type'] == 'ext':
        col = feat['name']
        pool_df[f'd_{col}'] = df_model[col].diff()
pool_df['resid'] = final_model.resid
pool_df = pool_df.dropna().reset_index(drop=True)
n_pool = len(pool_df)

history_vars = ['Balance_CHF_JPY', 'CHF_Share', 'Interest_Spread', 'FX_Volatility', 'Logit_Share']
sim_histories = {v: np.zeros((Config.NUM_SIMULATIONS, Config.SIMULATION_MONTHS)) for v in history_vars}
sim_phys_paths = np.zeros((Config.NUM_SIMULATIONS, Config.SIMULATION_MONTHS))

last_row = df_model.iloc[-1]
params = final_model.params

curr_state_full = {col: np.full(Config.NUM_SIMULATIONS, last_row[col]) for col in X_cols}
curr_runoff_chf = np.full(Config.NUM_SIMULATIONS, last_row['Balance_USD'] * last_row['CHF_Share'])
curr_runoff_usd = np.full(Config.NUM_SIMULATIONS, last_row['Balance_USD'])
target_usd = last_row['Balance_USD']

n_blocks = int(np.ceil(Config.SIMULATION_MONTHS / Config.BLOCK_SIZE))
block_starts = np.random.randint(0, n_pool - Config.BLOCK_SIZE + 1, size=(Config.NUM_SIMULATIONS, n_blocks))
sim_indices = np.zeros((Config.NUM_SIMULATIONS, Config.SIMULATION_MONTHS), dtype=int)
for i in range(Config.NUM_SIMULATIONS):
    cursor = 0
    for start in block_starts[i]:
        length = min(Config.BLOCK_SIZE, Config.SIMULATION_MONTHS - cursor)
        sim_indices[i, cursor:cursor+length] = np.arange(start, start+length)
        cursor += length
        if cursor >= Config.SIMULATION_MONTHS: break

for t in range(Config.SIMULATION_MONTHS):
    idx_t = sim_indices[:, t]
    next_state = {}
    
    # Lag Update
    for feat in Config.FEATURES:
        if feat['type'] == 'lag':
            name = feat['name']
            if name not in X_cols: continue
            src, lag = feat['source'], feat['lag']
            prev = next((f['name'] for f in Config.FEATURES if f['source']==src and f['lag']==lag-1), None)
            if prev: next_state[name] = curr_state_full[prev]
            elif src == 'Interest_Spread' and lag == 1:
                 l0 = next((f['name'] for f in Config.FEATURES if f['source']==src and f['lag']==0), None)
                 if l0: next_state[name] = curr_state_full[l0]

    # Ext Update
    for feat in Config.FEATURES:
        if feat['type'] == 'ext':
            name = feat['name']
            if name not in X_cols: continue
            delta = pool_df.iloc[idx_t][f'd_{name}'].values
            next_state[name] = curr_state_full[name] + delta
            if 'Spread' in name:
                cap = last_row[name] * Config.STRESS_SPREAD_FACTOR
                next_state[name] = np.minimum(next_state[name], cap)  # ここをコメントアウトすると、金利差の上限を除き過去準拠となる

    curr_state_full.update(next_state)
    
    pred_logit = np.full(Config.NUM_SIMULATIONS, params['const'])
    for col in final_vars:
        pred_logit += params[col] * curr_state_full[col]
    pred_logit += pool_df.iloc[idx_t]['resid'].values
    
    # Lag1 update for next loop
    for feat in Config.FEATURES:
        if feat['source'] == 'Logit_Share' and feat['lag'] == 1:
            curr_state_full[feat['name']] = pred_logit
            
    pred_share = 1.0 / (1.0 + np.exp(-pred_logit))
    
    # Balance (Logic A & B)
    curr_runoff_chf *= (1 - Config.RUNOFF_RATE)
    sim_phys_paths[:, t] = curr_runoff_chf
    
    curr_runoff_usd *= (1 - Config.RUNOFF_RATE)
    gap = np.maximum(target_usd - curr_runoff_usd, 0)
    curr_total_chf_usd = curr_runoff_chf + (gap * pred_share)
    
    # Record Paths
    sim_histories['Balance_CHF_JPY'][:, t] = curr_total_chf_usd * current_usdjpy
    sim_histories['CHF_Share'][:, t] = pred_share
    sim_histories['Logit_Share'][:, t] = pred_logit
    
    spread_var = next((f['name'] for f in Config.FEATURES if f['source']=='Interest_Spread' and f['lag']==0), None)
    if spread_var and spread_var in curr_state_full:
        sim_histories['Interest_Spread'][:, t] = curr_state_full[spread_var]
        
    vol_var = next((f['name'] for f in Config.FEATURES if f['source']=='FX_Volatility' and f['lag']==0), None)
    if vol_var and vol_var in curr_state_full:
        sim_histories['FX_Volatility'][:, t] = curr_state_full[vol_var]

# ---------------------------------------------------------
# 5. 結果出力 & 可視化
# ---------------------------------------------------------
print("\n--- [4] Visualization & Export ---")
dates_future = pd.date_range(start=df_model['Date'].iloc[-1], periods=Config.SIMULATION_MONTHS+1, freq='ME')
dates_combined = pd.concat([df_model['Date'], pd.Series(dates_future[1:])])

sim_eco_paths = sim_histories['Balance_CHF_JPY']
sim_eco_lb = np.percentile(sim_eco_paths, Config.CONFIDENCE_LEVEL * 100, axis=0)
sim_median = np.median(sim_eco_paths, axis=0)
sim_phys_mean = np.mean(sim_phys_paths, axis=0) * current_usdjpy

# Plot 1: Forecast with Annotation
fig, ax = plt.subplots(figsize=(12, 7))
hist_jpy = df_model['Balance_USD'] * df_model['CHF_Share'] * current_usdjpy
ax.plot(dates_combined, list(hist_jpy)+[np.nan]*Config.SIMULATION_MONTHS, label='Historical', color='black', linewidth=2)

plot_med = [np.nan]*len(hist_jpy) + list(sim_median)
plot_med[len(hist_jpy)-1] = hist_jpy.iloc[-1]
plot_eco = [np.nan]*len(hist_jpy) + list(sim_eco_lb)
plot_eco[len(hist_jpy)-1] = hist_jpy.iloc[-1]
plot_phys = [np.nan]*len(hist_jpy) + list(sim_phys_mean)
plot_phys[len(hist_jpy)-1] = hist_jpy.iloc[-1]

ax.plot(dates_combined, plot_med, label='Median Forecast', color='green', linewidth=2)
ax.plot(dates_combined, plot_eco, label='Logic B: Economic Floor (95% LB)', color='blue', linewidth=3)
ax.plot(dates_combined, plot_phys, label='Logic A: Physical Floor', color='red', linestyle='--', linewidth=2)

# Annotations (Values)
date_end = dates_future[-1]
ax.annotate(f'{sim_median[-1]:,.0f}', xy=(date_end, sim_median[-1]), xytext=(10, 0), textcoords='offset points', color='green', fontweight='bold', va='center')
ax.annotate(f'{sim_eco_lb[-1]:,.0f}', xy=(date_end, sim_eco_lb[-1]), xytext=(10, 0), textcoords='offset points', color='blue', fontweight='bold', va='center')
ax.annotate(f'{sim_phys_mean[-1]:,.0f}', xy=(date_end, sim_phys_mean[-1]), xytext=(10, 0), textcoords='offset points', color='red', fontweight='bold', va='center')

ax.set_title('CHF Loan Forecast with Final Values', fontsize=14)
ax.set_ylabel('CHF Outstanding (JPY)')
ax.legend(loc='upper left')
ax.grid(True, alpha=0.5)
plt.show()

# Plot 2: Variable Paths (Spaghetti Plots)
vars_to_plot = ['CHF_Share', 'Interest_Spread', 'FX_Volatility']
fig, axes = plt.subplots(len(vars_to_plot), 1, figsize=(12, 4*len(vars_to_plot)), sharex=True)
indices_to_plot = np.random.choice(Config.NUM_SIMULATIONS, 50, replace=False)

for i, var_name in enumerate(vars_to_plot):
    ax = axes[i]
    hist_vals = df_model[var_name] if var_name in df_model.columns else None
    sim_data = sim_histories[var_name]
    
    if hist_vals is not None:
        ax.plot(df_model['Date'], hist_vals, color='black', linewidth=2, label='Historical')
        last_val = hist_vals.iloc[-1]
        for idx in indices_to_plot:
            path_plot = np.concatenate([[last_val], sim_data[idx, :]])
            ax.plot(dates_future, path_plot, color='blue', alpha=0.1, linewidth=0.5)
            
    ax.set_title(f'Scenario Paths: {var_name}', fontsize=12)
    ax.grid(True, alpha=0.3)
    if i == 0: ax.legend(loc='upper left')

plt.tight_layout()
plt.show()

# ZIP Export
zip_filename = 'simulation_results_all.zip'
with zipfile.ZipFile(zip_filename, 'w', compression=zipfile.ZIP_DEFLATED) as zf:
    summ_df = pd.DataFrame({'Date': dates_future[1:]})
    summ_df['LogicA_Phys'] = sim_phys_mean
    summ_df['LogicB_Eco_95LB'] = sim_eco_lb
    summ_df['Median'] = sim_median
    zf.writestr('summary_forecast.csv', summ_df.to_csv(index=False))
    zf.writestr('historical_data.csv', df_model.to_csv(index=False))
    
    print("Exporting full simulation paths...")
    sim_dates = dates_future[1:]
    for var_name, data_matrix in sim_histories.items():
        if np.all(data_matrix == 0): continue
        path_df = pd.DataFrame(data_matrix.T, index=sim_dates, columns=[f'Sim_{i}' for i in range(Config.NUM_SIMULATIONS)])
        zf.writestr(f'paths_{var_name}.csv', path_df.to_csv(index=True, index_label='Date'))

print(f"\nCompleted! All data saved in '{zip_filename}'.")
